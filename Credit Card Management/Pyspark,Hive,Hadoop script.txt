hdfs dfs -mkdir /user/hduser/credcarddb

hdfs dfs -mkdir /user/hduser/credcarddb/inputdir

hdfs dfs -mkdir /user/hduser/credcarddb/outputdir





hive> create database sourcedb;

hive> create database targetdb;




				CUSTOMER


hive> Create table CUSTOMER(CUST_ID BIGINT,CUST_F_NAME VARCHAR(40),CUST_M_NAME VARCHAR(40),CUST_L_NAME VARCHAR(40),CUST_CC_NO BIGINT,CARD_TYPE VARCHAR(10),CARD_LIMIT INT,CARD_END_DATE DATE,CUST_SSN INT,CUST_STREET VARCHAR(38),CUST_CITY VARCHAR(30),CUST_STATE VARCHAR(30),CUST_COUNTRY VARCHAR(30),CUST_ZIP INT,CUST_PHONE VARCHAR(12),CUST_EMAIL VARCHAR(40)) row format delimited fields terminated by ','  tblproperties("skip.header.line.count"="1");

hive> load data local inpath '/home/hduser/dataset/training/Customer.csv' into table CUSTOMER;

				BRANCH



hive> Create table BRANCH(BRANCH_CODE INT,BRANCH_NAME VARCHAR (25),BRANCH_STREET VARCHAR (30),BRANCH_CITY VARCHAR (30),BRANCH_STATE VARCHAR(30),BRANCH_ZIP INT,BRANCH_PHONE VARCHAR (13))row format delimited fields terminated by ',' lines terminated by '\n' tblproperties("skip.header.line.count"="1");

hive> load data local inpath '/home/hduser/dataset/training/Branch.csv' into table BRANCH;

				TRAN_CREDIT_CARD



hive> Create table TRAN_CREDIT_CARD(TRAN_ID INT,TRAN_DATE DATE,CUST_ID BIGINT,CUST_CC_NO BIGINT,CUST_SSN BIGINT,BRANCH_CODE INT,TRANSACTION_TYPE VARCHAR(30),TRANSACTION_VALUE INT)row format delimited fields terminated by ',' lines terminated by '\n' tblproperties("skip.header.line.count"="1");

hive> load data local inpath '/home/hduser/dataset/training/Tran_creditcard.csv' into table TRAN_CREDIT_CARD;






===============================================================================================================
Requirement 1:



hive>create external table targetdb.monthly_bill(cust_id bigint,cust_f_name varchar(40),cust_l_name varchar(40),cust_cc_no bigint,card_type varchar(40),tran_year int,tran_month varchar(50),bill int,remark string) row format delimited fields terminated by ',' lines terminated by '\n' stored as parquet location '/user/hduser/credcarddb/outputdir/Monthly_Bills/';

>>spark.sql("insert into targetdb.monthly_bill select t.cust_id,upper(c.cust_f_name) as cust_f_name,upper(c.cust_l_name) as cust_l_name,c.cust_cc_no,upper(c.card_type) as card_type,year(t.tran_date) year,date_format(t.tran_date,'MMMM') as month,abs(sum(t.transaction_value)) as bill,case when sum(t.transaction_value)=0 then 'PAYMENT COMPLETED' else 'PENDING PAYMENT' end as remark from sourcedb.TRAN_CREDIT_CARD t join sourcedb.CUSTOMER c on c.cust_id=t.cust_id group by t.cust_id,c.cust_f_name,c.cust_m_name,c.cust_l_name,c.cust_cc_no,c.card_type,year(t.tran_date),date_format(t.tran_date,'MMMM') order by t.cust_id,year")


spark.sql("select * from targetdb.monthly_bill order by tran_year,case when tran_month='January' then 1 when tran_month='February' then 2 when tran_month='March' then 3 when tran_month='April' then 4 when tran_month='May' then 5 when tran_month='June' then 6 when tran_month='July' then 7 when tran_month='August' then 8 when tran_month='September' then 9 when tran_month='October' then 10 when tran_month='November' then 11 when tran_month='December' then 12 else NULL end limit 10").show()

-----------------------------------------------
Requirement:2
hive:

create external table targetdb.credcard_limit_exed(cust_id bigint,cust_f_name varchar(40),cust_l_name varchar(40),cust_cc_no bigint,card_type varchar(40),card_limit int,tran_year varchar(50),tran_month varchar(50),total_purchase int,amount_exceeded int,remark string) row format delimited fields terminated by ',' lines terminated by '\n' stored as parquet location '/user/hduser/credcarddb/outputdir/Card_Limit_Exceed/';

pyspark:

spark.sql("insert overwrite table targetdb.credcard_limit_exed select t.cust_id,upper(c.cust_f_name),upper(c.cust_l_name),c.cust_cc_no,c.card_type,c.card_limit,date_format(t.tran_date,'YYYY') as YEAR,date_format(t.tran_date,'MMMM') as MONTH,sum(t.transaction_value),sum(t.transaction_value)-c.card_limit,'ALERT CC TEAM' from sourcedb.tran_credit_card t join sourcedb.customer c on t.cust_id=c.cust_id where t.transaction_type='Purchase' group by t.cust_id,c.cust_f_name,c.cust_m_name, c.cust_l_name,c.card_type, c.cust_cc_no,c.card_limit,YEAR,MONTH having sum(t.transaction_value)>c.card_limit order by YEAR DESC, case when MONTH='JANUARY' then 1 when MONTH='FEBRUARY' then 2 when MONTH='MARCH' then 3 when MONTH='APRIL' then 4 when MONTH='MAY' then 5 when MONTH='JUNE' then 6 when MONTH='JULY' then 7 when MONTH='AUGUST' then 8 when MONTH='SEPTEMBER' then 9 when MONTH='OCTOBER' then 10 when MONTH='NOVEMBER' then 11 when MONTH='DECEMBER' then 12 else NULL end")



spark.sql("select * from targetdb.credcard_limit_exed limit 5").show()
-------------------------------------------------
Requirement:3

hive>create external table targetdb.over_due(cust_id bigint,cust_f_name varchar(40),cust_m_name varchar (40), cust_l_name varchar(40),cust_cc_no bigint,card_type varchar(40),tran_year int,tran_month varchar(50),pending_amount int,status string,remark string) row format delimited fields terminated by ',' lines terminated by '\n' stored as parquet location '/user/hduser/credcarddb/outputdir/Over_Due_Details/';

>>spark.sql("insert into target_credcarddb.over_due select t.cust_id,upper(c.cust_f_name),upper(c.cust_m_name),upper(c.cust_l_name),c.cust_cc_no,upper(c.card_type),year(t.tran_date) as year,upper(date_format(t.tran_date,'MMMM')) as month,sum(t.transaction_value),case when sum(t.transaction_value)>0 then 'PENDING PAYMENT' end,'CAUTION COLLECTION TEAM' from sourcedb.TRAN_CREDIT_CARD t join sourcedb.CUSTOMER c on c.cust_id=t.cust_id group by t.cust_id,c.cust_f_name,c.cust_m_name,c.cust_l_name,t.branch_code,c.cust_cc_no,c.card_type,year(t.tran_date),date_format(t.tran_date,'MMMM')  having sum(t.transaction_value)>0 order by t.cust_id,year,month").show()

hive:
insert overwrite directory '/user/hduser/credcarddb/outputdir/Over_Due_Remark' row format delimited fields terminated by ',' select t.cust_id,upper(c.cust_f_name),upper(c.cust_l_name),c.cust_cc_no,upper(c.card_type),year(t.tran_date) as tran_year,upper(date_format(t.tran_date,'MMMM')) as tran_month,sum(t.transaction_value),case when sum(t.transaction_value)>=25000 then 'POOR' when sum(t.transaction_value)>=10000 and sum(t.transaction_value)<25000 then 'NORMAL' else 'GOOD' end from sourcedb.tran_credit_card t join sourcedb.customer c on c.cust_id=t.cust_id group by t.cust_id,c.cust_f_name,c.cust_m_name,c.cust_l_name,t.branch_code,c.cust_cc_no,c.card_type,year(t.tran_date),date_format(t.tran_date,'MMMM') having sum(t.transaction_value)>0 order by t.cust_id,tran_year,tran_month;

pysaprk:
df=spark.sql("select t.cust_id as CUSTOMER_ID,upper(c.cust_f_name) as FIRST_NAME,upper(c.cust_l_name) AS LAST_NAME,c.cust_cc_no AS CREDIT_CARD_NO,upper(c.card_type) AS CARD_TYPE,year(t.tran_date) as YEAR,upper(date_format(t.tran_date,'MMMM')) as MONTH,sum(t.transaction_value) AS OVERDUE,case when sum(t.transaction_value)>=25000 then 'POOR' when sum(t.transaction_value)>=10000 and sum(t.transaction_value)<25000 then 'NORMAL' else 'GOOD' end AS REMARK from sourcedb.tran_credit_card t join sourcedb.customer c on c.cust_id=t.cust_id group by t.cust_id,c.cust_f_name,c.cust_m_name,c.cust_l_name,t.branch_code,c.cust_cc_no,c.card_type,year(t.tran_date),date_format(t.tran_date,'MMMM') having sum(t.transaction_value)>0 order by YEAR, case when MONTH='JANUARY' then 1 when MONTH='FEBRUARY' then 2 when MONTH='MARCH' then 3 when MONTH='APRIL' then 4 when MONTH='MAY' then 5 when MONTH='JUNE' then 6 when MONTH='JULY' then 7 when MONTH='AUGUST' then 8 when MONTH='SEPTEMBER' then 9 when MONTH='OCTOBER' then 10 when MONTH='NOVEMBER' then 11 when MONTH='DECEMBER' then 12 else NULL end")

df.repartition(1).write.format("csv").mode("overwrite").option("header","true").save("hdfs://localhost:50000/user/hduser/credcarddb/outputdir/CredCard_Anlz_Summ.csv")

df.show()
-------------------------------------------------------------
Requirement:4


df =spark.sql("select c.card_type,sum(t.transaction_value) as purchasedvalue   from sourcedb.tran_credit_card t join sourcedb.customer c on c.cust_id = t.cust_id AND t.transaction_type='Purchase' group by c.card_type order by purchasedvalue desc")


df.repartition(1).write.format("csv").mode("overwrite").option("header","true").save("/home/hduser/CARDRANK/cardrank.csv")

Jupyter:

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df=pd.read_csv("/home/hduser/CARDRANK/cardrank.csv")  # change the file path


c=["green","blue","red"]  # we can change colors here
plt.figure(figsize=(6, 6))
plots = sns.barplot(x="card_type", y="transaction_value", data=df,palette=c)
for bar in plots.patches:
    plots.annotate(int(bar.get_height()), 
                   (bar.get_x() + bar.get_width() / 2, 
                    bar.get_height()), ha='center', va='center',
                   size=15, xytext=(0, 8),
                   textcoords='offset points')

plt.xlabel("Top 3 card types", size=14)

plt.ylabel("Transaction value in lakhs", size=14)
  
plt.title("Top 3 card purchase values in lakhs",size=16)

plt.show()








====================================================================

create external table targetdb.mont_bill(cust_id BIGINT, cust_f_name VARCHAR(40),cust_l_name(40), cust_cc_no BIGINT,card_type VARCHAR(40),tran_year INT,tran_month VARCHAR(15),purchase INT,payment INT, bill BIGINT) row format delimited fields terminated by ',' lines terminated by '\n' stored as parquet location '/user/hduser/credcarddb/outputdir/monthly_bills/';



>>> spark.sql( "INSERT OVERWRITE TABLE targetdb.mont_bill SELECT id,fname,lname, cc_no, c_type, year, month, SUM(purchase) AS Tot_Purchase, SUM(payment) AS Tot_Payment, SUM(bill) AS bill  FROM  (SELECT t.cust_id as id,c.cust_f_name as fname,c.cust_l_name as lname, c.cust_cc_no AS cc_no, c.card_type as c_type, year(t.tran_date) AS year, date_format(t.tran_date,'MMMM') as month, CASE WHEN t.tran_type ='Purchase' THEN SUM(t.transaction_value) ELSE 0 END AS purchase, CASE WHEN t.tran_type ='Payment' THEN SUM(t.transaction_value) ELSE 0 END AS payment,  SUM(t.transaction_value) as bill FROM sourcedb.tran_credit_card t JOIN sourcedb.customer c ON t.cust_id=c.cust_id  GROUP BY t.cust_id,fname, lname, c.cust_cc_no, c.card_type, year(t.tran_date), date_format(t.tran_date,'MMMM'), t.tran_type) temp_table  GROUP BY id,fname, lname,cc_no, c_type, year, month ORDER BY year, month, cc_no")
































